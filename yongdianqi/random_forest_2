import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_selection import SelectFromModel
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report

# 读取CSV文件
df = pd.read_csv('/kaggle/input/combined-modified-files/combined_modified_files.csv')

# 提取输入特征和输出特征
X = df.iloc[:, :1026].values
y = df.iloc[:, 1026].values

# 划分训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 数据预处理：标准化
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# 特征选择：使用随机森林的特征重要性
# 首先训练一个随机森林模型来评估特征的重要性
rf = RandomForestClassifier(random_state=42)
rf.fit(X_train_scaled, y_train)

# 使用SelectFromModel来选择特征
selector = SelectFromModel(rf, threshold='median')  # 选择重要性中位数的特征
X_train_selected = selector.transform(X_train_scaled)
X_test_selected = selector.transform(X_test_scaled)

# 模型调优：网格搜索
param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [None, 10, 20],
    'min_samples_split': [2, 5, 10]
}
grid_search = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=5, scoring='accuracy', n_jobs=-1)

# 进行网格搜索
grid_search.fit(X_train_selected, y_train)

# 输出最佳参数
print(f'最佳参数: {grid_search.best_params_}')

# 使用最佳参数重新训练模型
best_model = grid_search.best_estimator_
best_model.fit(X_train_selected, y_train)

# 评估模型
y_pred = best_model.predict(X_test_selected)
print(classification_report(y_test, y_pred))
